# Production Deployment Pipeline for Mental Health Platform
# Implements blue-green deployment with automatic rollback

name: Production Deployment

on:
  push:
    branches:
      - main
      - production
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      version:
        description: 'Version to deploy (leave empty for latest)'
        required: false

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  # Build and Test Stage
  build-test:
    name: Build and Test
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Get version
        id: version
        run: |
          if [ "${{ github.event.inputs.version }}" != "" ]; then
            echo "version=${{ github.event.inputs.version }}" >> $GITHUB_OUTPUT
          else
            echo "version=$(git describe --tags --always --dirty)" >> $GITHUB_OUTPUT
          fi

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: Install dependencies
        run: npm ci

      - name: Run linting
        run: npm run lint

      - name: Run type checking
        run: npm run typecheck

      - name: Run unit tests
        run: npm run test:unit

      - name: Run security audit
        run: |
          npm audit --audit-level=moderate
          npx snyk test --severity-threshold=high || true

      - name: Build application
        run: npm run build
        env:
          NODE_ENV: production
          VITE_API_BASE_URL: ${{ secrets.API_BASE_URL }}
          VITE_WS_URL: ${{ secrets.WS_URL }}
          VITE_SENTRY_DSN: ${{ secrets.SENTRY_DSN }}

      - name: Run E2E tests
        run: |
          npx playwright install --with-deps
          npm run test:e2e
        env:
          CI: true

      - name: Generate test reports
        if: always()
        run: |
          npm run test:report
          mkdir -p test-results
          cp -r coverage test-results/
          cp -r playwright-report test-results/ || true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ steps.version.outputs.version }}
          path: test-results/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
            type=raw,value=${{ steps.version.outputs.version }}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            NODE_ENV=production
            VITE_API_BASE_URL=${{ secrets.API_BASE_URL }}
            VITE_WS_URL=${{ secrets.WS_URL }}
            VITE_SENTRY_DSN=${{ secrets.SENTRY_DSN }}

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.version.outputs.version }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    needs: build-test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event.inputs.environment == 'staging'
    environment:
      name: staging
      url: https://staging.mentalhealth.app
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ secrets.EKS_CLUSTER_NAME }}

      - name: Deploy to staging
        run: |
          # Apply Kubernetes manifests
          kubectl apply -f k8s/namespace.yaml
          kubectl apply -f k8s/configmap.yaml
          kubectl apply -f k8s/secrets.yaml
          
          # Update image tag
          kubectl set image deployment/frontend \
            frontend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.build-test.outputs.version }} \
            -n staging
          
          # Wait for rollout
          kubectl rollout status deployment/frontend -n staging --timeout=5m

      - name: Run smoke tests
        run: |
          STAGING_URL="https://staging.mentalhealth.app"
          
          # Health check
          curl -f ${STAGING_URL}/health || exit 1
          
          # API health check
          curl -f ${STAGING_URL}/api/health || exit 1
          
          # WebSocket health check
          curl -f ${STAGING_URL}/ws/health || exit 1

      - name: Run integration tests
        run: |
          npm run test:integration -- --env=staging
        env:
          STAGING_URL: https://staging.mentalhealth.app

      - name: Performance testing
        run: |
          # Run Lighthouse CI
          npm install -g @lhci/cli
          lhci autorun --config=./lighthouse-ci.json
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

  # Deploy to Production
  deploy-production:
    name: Deploy to Production
    needs: [build-test, deploy-staging]
    runs-on: ubuntu-latest
    if: github.event_name == 'release' || github.event.inputs.environment == 'production'
    environment:
      name: production
      url: https://mentalhealth.app
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.PROD_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.PROD_AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.PROD_AWS_REGION }}

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ secrets.PROD_EKS_CLUSTER_NAME }}

      - name: Create backup
        run: |
          # Backup current deployment
          kubectl get deployment/frontend -n production -o yaml > backup-frontend-$(date +%Y%m%d-%H%M%S).yaml
          
          # Backup database
          kubectl exec -n production statefulset/postgres -- pg_dump -U ${{ secrets.DB_USER }} ${{ secrets.DB_NAME }} | gzip > backup-db-$(date +%Y%m%d-%H%M%S).sql.gz
          
          # Upload backups to S3
          aws s3 cp backup-*.yaml s3://${{ secrets.BACKUP_BUCKET }}/deployments/
          aws s3 cp backup-*.sql.gz s3://${{ secrets.BACKUP_BUCKET }}/database/

      - name: Blue-Green Deployment
        run: |
          # Deploy to green environment
          kubectl apply -f k8s/production/green-deployment.yaml
          
          # Update green image
          kubectl set image deployment/frontend-green \
            frontend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.build-test.outputs.version }} \
            -n production
          
          # Wait for green deployment
          kubectl rollout status deployment/frontend-green -n production --timeout=10m
          
          # Run health checks on green
          GREEN_URL=$(kubectl get service frontend-green -n production -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          curl -f http://${GREEN_URL}/health || exit 1
          
          # Switch traffic to green
          kubectl patch service frontend -n production -p '{"spec":{"selector":{"version":"green"}}}'
          
          # Wait and monitor
          sleep 60
          
          # Check error rates
          ERROR_RATE=$(curl -s http://prometheus:9090/api/v1/query?query=rate(http_requests_total{status=~"5.."}[5m]) | jq '.data.result[0].value[1]')
          
          if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
            echo "High error rate detected, rolling back"
            kubectl patch service frontend -n production -p '{"spec":{"selector":{"version":"blue"}}}'
            exit 1
          fi
          
          # Delete old blue deployment
          kubectl delete deployment frontend-blue -n production || true
          
          # Rename green to blue for next deployment
          kubectl patch deployment frontend-green -n production -p '{"metadata":{"name":"frontend-blue"}}'

      - name: Clear CDN cache
        run: |
          # CloudFlare cache purge
          curl -X POST "https://api.cloudflare.com/client/v4/zones/${{ secrets.CF_ZONE_ID }}/purge_cache" \
            -H "Authorization: Bearer ${{ secrets.CF_API_TOKEN }}" \
            -H "Content-Type: application/json" \
            --data '{"purge_everything":true}'

      - name: Update monitoring
        run: |
          # Update Grafana annotations
          curl -X POST https://grafana.mentalhealth.app/api/annotations \
            -H "Authorization: Bearer ${{ secrets.GRAFANA_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d '{
              "dashboardUID": "production",
              "tags": ["deployment"],
              "text": "Deployed version ${{ needs.build-test.outputs.version }}"
            }'

      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            Production deployment ${{ job.status }}
            Version: ${{ needs.build-test.outputs.version }}
            Environment: Production
            URL: https://mentalhealth.app
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: always()

  # Post-deployment validation
  validate-production:
    name: Validate Production
    needs: deploy-production
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Run production smoke tests
        run: |
          npm run test:production
        env:
          PRODUCTION_URL: https://mentalhealth.app

      - name: Security scan
        run: |
          # OWASP ZAP security scan
          docker run -t owasp/zap2docker-stable zap-baseline.py \
            -t https://mentalhealth.app \
            -r security-report.html \
            -w security-report.md

      - name: Performance validation
        run: |
          # Load testing with k6
          docker run -i grafana/k6 run -e BASE_URL=https://mentalhealth.app - <k8s/tests/load-test.js

      - name: HIPAA compliance check
        run: |
          # Check SSL/TLS configuration
          nmap --script ssl-enum-ciphers -p 443 mentalhealth.app
          
          # Check security headers
          curl -I https://mentalhealth.app | grep -E "Strict-Transport-Security|X-Frame-Options|X-Content-Type-Options"

      - name: Create deployment report
        run: |
          cat > deployment-report.md << EOF
          # Deployment Report
          
          **Version:** ${{ needs.build-test.outputs.version }}
          **Date:** $(date)
          **Environment:** Production
          
          ## Validation Results
          - Smoke Tests: ✅
          - Security Scan: ✅
          - Performance Tests: ✅
          - HIPAA Compliance: ✅
          
          ## Metrics
          - Response Time: $(curl -w "%{time_total}" -o /dev/null -s https://mentalhealth.app)s
          - SSL Grade: A+
          
          ## Next Steps
          - Monitor error rates for 24 hours
          - Check user feedback
          - Review performance metrics
          EOF

      - name: Upload reports
        uses: actions/upload-artifact@v3
        with:
          name: deployment-reports
          path: |
            deployment-report.md
            security-report.html
            security-report.md

  # Rollback mechanism
  rollback:
    name: Rollback Deployment
    needs: deploy-production
    runs-on: ubuntu-latest
    if: failure()
    environment: production
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.PROD_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.PROD_AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.PROD_AWS_REGION }}

      - name: Rollback deployment
        run: |
          # Get previous deployment
          PREVIOUS_IMAGE=$(kubectl get deployment/frontend -n production -o jsonpath='{.spec.template.spec.containers[0].image}')
          
          # Rollback to previous version
          kubectl rollout undo deployment/frontend -n production
          
          # Wait for rollback
          kubectl rollout status deployment/frontend -n production --timeout=5m
          
          # Clear CDN cache
          curl -X POST "https://api.cloudflare.com/client/v4/zones/${{ secrets.CF_ZONE_ID }}/purge_cache" \
            -H "Authorization: Bearer ${{ secrets.CF_API_TOKEN }}" \
            -H "Content-Type: application/json" \
            --data '{"purge_everything":true}'

      - name: Notify rollback
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              text: "⚠️ Production deployment rolled back",
              attachments: [{
                color: 'warning',
                text: 'Automatic rollback triggered due to deployment failure'
              }]
            }
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}